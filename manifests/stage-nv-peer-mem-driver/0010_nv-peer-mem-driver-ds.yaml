# Copyright 2020 NVIDIA
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: nv-peer-mem-driver-{{ .RuntimeSpec.CPUArch }}-{{ .RuntimeSpec.OSName }}{{ .RuntimeSpec.OSVer }}
  name: nv-peer-mem-driver-{{ .RuntimeSpec.CPUArch }}-{{ .RuntimeSpec.OSName }}{{ .RuntimeSpec.OSVer }}-ds
  namespace: {{ .RuntimeSpec.Namespace }}
spec:
  selector:
    matchLabels:
      app: nv-peer-mem-driver-{{ .RuntimeSpec.CPUArch }}-{{ .RuntimeSpec.OSName }}{{ .RuntimeSpec.OSVer }}
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        app: nv-peer-mem-driver-{{ .RuntimeSpec.CPUArch }}-{{ .RuntimeSpec.OSName }}{{ .RuntimeSpec.OSVer }}
    spec:
      tolerations:
        # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
        # This, along with the annotation above marks this pod as a critical add-on.
        - key: CriticalAddonsOnly
          operator: Exists
        - key: node-role.kubernetes.io/master
          operator: Exists
          effect: NoSchedule
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      hostNetwork: true
      containers:
        - image: {{ .CrSpec.Repository }}/{{ .CrSpec.Image }}-{{ .CrSpec.Version }}:{{ .RuntimeSpec.CPUArch }}-{{ .RuntimeSpec.OSName }}{{ .RuntimeSpec.OSVer }}
          imagePullPolicy: IfNotPresent
          name: nv-peer-mem-driver-container
          securityContext:
            privileged: true
            seLinuxOptions:
              level: "s0"
          env:
            - name: HTTP_PROXY
              value: {{ .RuntimeSpec.HTTPProxy }}
            - name: HTTPS_PROXY
              value: {{ .RuntimeSpec.HTTPSProxy }}
            - name: NO_PROXY
              value: {{ .RuntimeSpec.NoProxy }}
          volumeMounts:
            - name: run-mlnx-ofed
              mountPath: /run/mellanox/drivers
              mountPropagation: HostToContainer
            - name: run-nvidia
              mountPath: /run/nvidia/drivers
              mountPropagation: HostToContainer
          startupProbe:
            exec:
              command:
                [sh, -c, 'ls /.driver-ready']
            initialDelaySeconds: 10
            failureThreshold: 60
            successThreshold: 1
            periodSeconds: 5
          livenessProbe:
            exec:
              command:
                [sh, -c, 'lsmod | grep nv_peer_mem']
            periodSeconds: 30
            initialDelaySeconds: 30
            failureThreshold: 1
            successThreshold: 1
          readinessProbe:
            exec:
              command:
                [sh, -c, 'lsmod | grep nv_peer_mem']
            periodSeconds: 30
            initialDelaySeconds: 10
            failureThreshold: 1
      volumes:
        - name: run-mlnx-ofed
          hostPath:
            path: /run/mellanox/drivers
        - name: run-nvidia
          hostPath:
            path: {{ .CrSpec.GPUDriverSourcePath }}
      nodeSelector:
        feature.node.kubernetes.io/pci-15b3.present: "true"
        nvidia.com/gpu.present: "true"
